{
    "tokenize.py": {
        "modified": "2005-10-03 03:18:16",
        "size": "11.67KB",
        "md5": "801e675b01cd39ebf6473605ec0abf43",
        "sha256": "28ecba9521f00430854cb3f9ab978d842d72651d49f9a1c5b3a0561569ac9c4f"
    },
    "Metadata": {
        "Content-Encoding": "ISO-8859-1",
        "Content-Type": "text/plain; charset=ISO-8859-1",
        "X-Parsed-By": [
            "org.apache.tika.parser.DefaultParser",
            "org.apache.tika.parser.csv.TextAndCSVParser"
        ],
        "X-TIKA:content_handler": "ToTextContentHandler",
        "X-TIKA:embedded_depth": "0",
        "X-TIKA:parse_time_millis": "1",
        "resourceName": "b'tokenize.py'"
    }
}